# MedGemma Attention Visualization

This notebook demonstrates how to load the `google/medgemma-4b-it` model and visualize its attention scores. [1][2][3]  
By inspecting the attention mechanism, we can gain insight into which parts of an input prompt the model focuses on when generating a response.

## Notebook Highlights

- **Heatmaps** – Show the attention patterns across different layers and heads for a single prompt.  
- **Bar charts** – Break down which specific input tokens a newly generated token is “looking at.”  
- **Multi‑step prompt analysis** – Illustrates how the model’s focus shifts as it addresses different tasks within a single, more complex prompt.


## License

This notebook is provided under the **MIT License**.
